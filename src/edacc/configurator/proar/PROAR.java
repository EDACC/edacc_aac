package edacc.configurator.proar;

import java.io.File;
import java.math.BigInteger;
import java.util.ArrayList;
import java.util.Collections;
import java.util.Date;
import java.util.HashMap;
import java.util.HashSet;
import java.util.LinkedList;
import java.util.List;
import java.util.Map;
import java.util.Random;
import java.util.Scanner;

import edacc.api.API;
import edacc.api.APIImpl;
import edacc.configurator.proar.algorithm.PROARMethods;
import edacc.model.ConfigurationScenarioDAO;
import edacc.model.Course;
import edacc.model.DatabaseConnector;
import edacc.model.ExperimentDAO;
import edacc.model.ExperimentResult;
import edacc.parameterspace.ParameterConfiguration;
import edacc.parameterspace.graph.ParameterGraph;

public class PROAR {

	private static final boolean generateSCForNextLevel = true;
	private static final boolean useCapping = false;
	private static final boolean deleteSolverConfigs = true;
	
	private int incumbentNumber = 0;
	private String experimentName;
	
	private API api;
	private int idExperiment;
	private int jobCPUTimeLimit;
	private String algorithm;
	private Random rng;
	private PROARMethods methods;
	private int maxCPUCount;
	private int minCPUCount;

	/** The statistics function to be used */
	private StatisticFunction statistics;

	/** inidcates if the results of the solver of deterministic nature or not */
	private boolean deterministic;

	/** maximum allowed tuning time = sum over all jobs in seconds */
	private float maxTuningTime;
	
	private long startTime;

	/**
	 * total cumulated time of all jobs the configurator has started so far in
	 * seconds
	 */
	private float cumulatedCPUTime;

	/** the best solver configuration found so far */
	private SolverConfiguration bestSC;

	/**
	 * List of all solver configuration that turned out to be better than the
	 * best configuration
	 */
	private List<SolverConfiguration> listBestSC;

	/**
	 * List of all NEW solver configuration that are going to be raced against
	 * the best
	 */
	private List<SolverConfiguration> listNewSC;

	/**
	 * If within the Experiment there is an other Solver that the configurator
	 * has to beat then raceCondition should be true. The configurator will then
	 * try to use the information about the results of this solver to try to
	 * beat him according to the statistic and metric function.
	 * */
	private boolean raceCondition;

	/**
	 * If raceCondigition == true then there has to be a competitior which the
	 * configurator will try to beat!
	 */
	private SolverConfiguration competitor;

	/**
	 * just for debugging
	 */
	private int level;
	/**
	 * The number of jobs that a configuration gets when its parcours is
	 * expanded
	 */
	private int parcoursExpansion;
	/**
	 * The maximum length of the parcours that will be generated by the
	 * configurator as a factor of the number of instances; i.e.: if the
	 * maxParcoursExpansionFactor = 10 and we have 250 instances in the
	 * configuration experiment then the maximum length of the parcours will be
	 * 2500.
	 */
	private int maxParcoursExpansionFactor;

	private int initialDefaultParcoursLength;

	private int statNumSolverConfigs;
	private int statNumJobs;

	private ParameterGraph graph;
	public PROAR(PROARParameters params) throws Exception {
		api = new APIImpl();
		api.connect(params.hostname, params.port, params.database, params.user, params.password);
		this.graph = api.loadParameterGraphFromDB(params.idExperiment);
		this.idExperiment = params.idExperiment;
		this.jobCPUTimeLimit = params.jobCPUTimeLimit;
		this.algorithm = params.algorithm;
		this.statistics = new StatisticFunction(api.costFunctionByName(params.costFunc), params.minimize);
		this.parcoursExpansion = params.pe;
		this.maxParcoursExpansionFactor = params.mpef;
		this.initialDefaultParcoursLength = params.ipd;
		this.maxTuningTime = params.maxTuningTime;
		rng = new edacc.util.MersenneTwister(params.seed);
		listBestSC = new ArrayList<SolverConfiguration>();
		listNewSC = new ArrayList<SolverConfiguration>();
		this.statNumSolverConfigs = 0;
		this.statNumJobs = 0;
		this.maxCPUCount = params.maxCPUCount;
		this.minCPUCount = params.minCPUCount;
		// TODO: Die beste config auch noch mittels einer methode bestimmen!
		methods = (PROARMethods) ClassLoader.getSystemClassLoader()
				.loadClass("edacc.configurator.proar.algorithm." + algorithm).getDeclaredConstructors()[0].newInstance(
				api, idExperiment, statistics, rng, params.configuratorMethodParams);
	}

	/**
	 * Checks if there are solver configurations in the experiment that would
	 * match the configuration scenario if there are more than one such
	 * configuration it will pick the best one as the best configuration found
	 * so far
	 * 
	 * @throws Exception
	 */
	private void initializeBest() throws Exception {
		// TODO: the best one might not match the configuration scenario
		// graph.validateParameterConfiguration(config) should test this,
		// but is currently not implemented and will return false.
		
		List<Integer> solverConfigIds = api.getSolverConfigurations(idExperiment, "default");
		if (solverConfigIds.isEmpty()) {
			solverConfigIds = api.getSolverConfigurations(idExperiment);
			log("c Found " + solverConfigIds.size() + " solver configuration(s)");
		} else {
			log("c Found " + solverConfigIds.size() + " default configuration(s)");
		}
		List<SolverConfiguration> solverConfigs = new LinkedList<SolverConfiguration>();
		int maxRun = -1;
		for (int id : solverConfigIds) {
			int runCount = api.getNumJobs(id);
			if (runCount > maxRun) {
				solverConfigs.clear();
				maxRun = runCount;
			}
			if (runCount == maxRun) {
				ParameterConfiguration pConfig = api.getParameterConfiguration(idExperiment, id);
				solverConfigs.add(new SolverConfiguration(id, pConfig, statistics, level));
			}
		}
		log("c " + solverConfigs.size() + " solver configs with max run");
		
		
		Course c = ConfigurationScenarioDAO.getConfigurationScenarioByExperimentId(idExperiment).getCourse();
		for (int sc_index = solverConfigs.size()-1; sc_index >= 0; sc_index--) {
			SolverConfiguration sc = solverConfigs.get(sc_index);
			HashSet<InstanceIdSeed> iis = new HashSet<InstanceIdSeed>();
			for (ExperimentResult job : api.getRuns(idExperiment, sc.getIdSolverConfiguration())) {
				sc.putJob(job);
				iis.add(new InstanceIdSeed(job.getInstanceId(), job.getSeed()));
			}
			boolean courseValid = true;
			boolean courseEnded = false;
			for (int i = 0; i < c.getLength(); i++) {
				InstanceIdSeed tmp = new InstanceIdSeed(c.get(i).instance.getId(), c.get(i).seed);
				courseValid = !(courseEnded && iis.contains(tmp));
				courseEnded = courseEnded || !iis.contains(tmp);
				if (!courseValid) {
					log("c Course invalid at instance number " + i + " instance: " + c.get(i).instance.getName());
					break;
				}
			}
			if (!courseValid) {
				log("c Removing solver configuration " + api.getSolverConfigName(sc.getIdSolverConfiguration()) + " caused by invalid course.");
				solverConfigs.remove(sc_index);
			}
		}
		
		log("c Determining best solver configuration from " + solverConfigs.size() + " solver configurations");
		
		if (solverConfigs.isEmpty()) {
			// no good solver configs in db
			log("c Generating a random solver configuration");

			ParameterConfiguration config = graph.getRandomConfiguration(rng);
			int idSolverConfiguration = api.createSolverConfig(idExperiment, config,
					"First Random Configuration " + api.getCanonicalName(idExperiment, config) + " level " + level);
			bestSC = new SolverConfiguration(idSolverConfiguration, api.getParameterConfiguration(idExperiment,
					idSolverConfiguration), statistics, level);
		} else {
			Collections.sort(solverConfigs);
			bestSC = solverConfigs.get(solverConfigs.size()-1);
			log("c Best solver configuration: " + api.getSolverConfigName(bestSC.getIdSolverConfiguration()));
			
		}
	}

	/**
	 * Recheck if there is a configuration in the Experiment that was created by
	 * someone else(other configurator or human) and is better then the current
	 * bestSC.
	 * 
	 * @return solver configuration ID that is better than the current bestSC or
	 *         -1 else
	 */
	private int recheck() {
		// TODO : implement
		return -1;
	}

	/**
	 * Determines if the termination criteria holds
	 * 
	 * @return true if the termination criteria is met;
	 */
	private boolean terminate() {
		if (this.maxTuningTime < 0)
			return false;
		// at the moment only the time budget is taken into consideration
		float exceed = this.cumulatedCPUTime - this.maxTuningTime;
		if (exceed > 0) {
			log("c Maximum allowed CPU time exceeded with: " + exceed + " seconds!!!");
			return true;
		} else
			return false;
	}

	/**
	 * Add num additional runs/jobs from the parcours to the configuration sc.
	 * 
	 * @throws Exception
	 */
	private void expandParcoursSC(SolverConfiguration sc, int num) throws Exception {
		// TODO implement
		// fuer deterministische solver sollte man allerdings beachten,
		// dass wenn alle instanzen schon verwendet wurden das der parcours
		// nicht weiter erweitert werden kann.
		// fuer probabilistische solver kann der parcours jederzeit erweitert
		// werden, jedoch
		// waere ein Obergrenze sinvoll die als funktion der anzahl der
		// instanzen definiert werden sollte
		// z.B: 10*#instanzen
		DatabaseConnector.getInstance().getConn().setAutoCommit(false);
		try {
			for (int i = 0; i < num; i++) {
				statNumJobs++;
				int idJob = api.launchJob(idExperiment, sc.getIdSolverConfiguration(), jobCPUTimeLimit, rng);
				api.setJobPriority(idJob, Integer.MAX_VALUE);
				sc.putJob(api.getJob(idJob)); // add the job to the solver
											// configuration own job store
			}
		} finally {
			DatabaseConnector.getInstance().getConn().setAutoCommit(true);
		}
	}

	/**
	 * Determines how many new solver configuration can be taken into
	 * consideration.
	 * 
	 * @throws Exception
	 */
	private int computeOptimalExpansion() throws Exception {
		return Math.max(0, 4*api.getComputationCoreCount(idExperiment) - listNewSC.size());
		/*
		 * TODO: was geschickteres implementieren, denn von diesem Wert haengt
		 * sehr stark der Grad der parallelisierung statt. denkbar ware noch
		 * api.getNumComputingUnits(); wenn man die Methode haette. eine andere
		 * geschicktere Moeglichkeit ist es: Anzahl cores = numCores Größe der
		 * besseren solver configs in letzter runde = numBests Anzahl der jobs
		 * die in der letzten Iteration berechnet wurden = numJobs Anzahl der
		 * neuen solver configs beim letzten Aufruf zurückgeliefert wurden =
		 * lastExpansion CPUTimeLimit = time Dann kann man die Anzahl an neuen
		 * konfigs berechnen durch newNumConfigs = TODO
		 */
	}

	/**
	 * adds random num new runs/jobs from the solver configuration "from" to the
	 * solver configuration "toAdd"
	 * 
	 * @throws Exception
	 */
	private int addRandomJob(int num, SolverConfiguration toAdd, SolverConfiguration from, int priority)
			throws Exception {
		toAdd.updateJobsStatus();
		from.updateJobsStatus();
		// compute a list with num jobs that "from" has computed and "toadd" has
		// not in its job list
		List<InstanceIdSeed> instanceIdSeedList = toAdd.getInstanceIdSeed(from, num, rng);
		int generated = 0;
		DatabaseConnector.getInstance().getConn().setAutoCommit(false);
		try {
			for (InstanceIdSeed is : instanceIdSeedList) {
				statNumJobs++;
				int idJob = api.launchJob(idExperiment, toAdd.getIdSolverConfiguration(), is.instanceId,
					BigInteger.valueOf(is.seed), jobCPUTimeLimit, priority);
				toAdd.putJob(api.getJob(idJob));
				generated++;
			}
		} finally {
			DatabaseConnector.getInstance().getConn().setAutoCommit(true);
		}
		return generated;
	}

	public void start() throws Exception {
		if (maxCPUCount == 0) {
			maxCPUCount = Integer.MAX_VALUE;
		}
		while (true) {
			int coreCount = api.getComputationCoreCount(idExperiment);
			if (coreCount >= minCPUCount && coreCount <= maxCPUCount) {
				break;
			}
			log("c Current core count: " + coreCount);
			log("c Waiting for #cores to satisfy: " + minCPUCount + " <= #cores <= " + maxCPUCount);
			Thread.sleep(10000);
		}
		log("c Starting PROAR.");
		startTime = System.currentTimeMillis();
		experimentName = ExperimentDAO.getById(idExperiment).getName();
		// first initialize the best individual if there is a default or if
		// there are already some solver configurations in the experiment
		level = 0;
		cumulatedCPUTime = 0.f;
		initializeBest();// TODO: mittels dem Classloader überschreiben
		bestSC.updateJobsStatus(); // don't add best scs time to cumulatedCPUTime
		if (bestSC == null) {
			throw new RuntimeException("best not initialized");
		}
		bestSC.setIncumbentNumber(incumbentNumber++);
		log("i " + getWallTime() + " ," + bestSC.getCost() + ", n.A.," + bestSC.getIdSolverConfiguration() + ", n.A.," + bestSC.getParameterConfiguration().toString());
		
		int expansion;
		int num_instances = ConfigurationScenarioDAO.getConfigurationScenarioByExperimentId(idExperiment).getCourse()
				.getInitialLength();

		if (num_instances == 0) {
			log("e Error: no instances in course.");
			return;
		}
		int numLostSC = 0;
		int numLostSCNextLevel = 0;
		while (!terminate()) {
			level++;
			log("c Beginning level " + level);
			// bestSC.updateJobsStatus(); das ist glaube ich doppelt gemoppelt
			// denn im übernächsten if wird auf jeden Fall
			// bestSC.updateJobsSatus() ausgeführt!
			// expand the parcours of the bestSC
			expansion = 0;
			if (bestSC.getJobCount() < maxParcoursExpansionFactor * num_instances && level == 1) {
				//expansion = Math.min(maxParcoursExpansionFactor * num_instances - bestSC.getJobCount(),
				//		parcoursExpansion);
				//if (level == 1) {
				expansion = Math.min(maxParcoursExpansionFactor * num_instances - bestSC.getJobCount(), initialDefaultParcoursLength);
				//}
				expandParcoursSC(bestSC, expansion);
			}
			if (expansion > 0) {
				log("c Expanding parcours of best solver config " + bestSC.getIdSolverConfiguration() + " by "
						+ expansion);
			}
			// update the status of the jobs of bestSC and if first level wait
			// also for jobs to finish
			if (level == 1) {
				log("c Waiting for currently best solver config " + bestSC.getIdSolverConfiguration()
						+ " to finish " + expansion + "job(s)");
				while (true) {
					cumulatedCPUTime += bestSC.updateJobsStatus();
					if (bestSC.getNotStartedJobs().isEmpty() && bestSC.getRunningJobs().isEmpty()) {
						break;
					}
					Thread.sleep(1000);
				}
			} else {
				cumulatedCPUTime += bestSC.updateJobsStatus();
			}
			updateSolverConfigName(bestSC, true);
			// update the cost of the configuration in the EDACC solver
			// configuration tables
			api.updateSolverConfigurationCost(bestSC.getIdSolverConfiguration(), bestSC.getCost(),
					statistics.getCostFunction());
			log("c Generating new Solver Configurations.");
			log("c There are currently " + listNewSC.size()
					+ " solver configurations for the current level (" + level + ") generated in the last level.");

			boolean currentLevelFinished = false;
			numLostSC = numLostSCNextLevel;
			numLostSCNextLevel = 0;
			// compute the number of new solver configs that should be generated
			// for this level
			int generateNumSCForCurrentLevel = computeOptimalExpansion();
			int generateNumSCForNextLevel = 0;
			// only when all jobs of the current level are finished we can
			// continue
			while (!currentLevelFinished) {
				currentLevelFinished = true;
				if (generateNumSCForCurrentLevel > 0 || generateNumSCForNextLevel > 0) {
					int numNewSC = 0;
					int generateForLevel;
					if (generateNumSCForCurrentLevel > 0) {
						generateForLevel = level;
						if (generateNumSCForCurrentLevel >= 210) {
							generateNumSCForCurrentLevel -= 210;
							numNewSC = 210;
						} else {
							numNewSC = generateNumSCForCurrentLevel;
							generateNumSCForCurrentLevel = 0;
						}
					} else {
						generateForLevel = level + 1;
						if (generateNumSCForNextLevel >= 210) {
							generateNumSCForNextLevel -= 210;
							numNewSC = 210;
						} else {
							numNewSC = generateNumSCForNextLevel;
							generateNumSCForNextLevel = 0;
						}
					}
					
					List<SolverConfiguration> tmpList;
					DatabaseConnector.getInstance().getConn().setAutoCommit(false);
					try {
						tmpList = methods.generateNewSC(numNewSC, listBestSC, bestSC, generateForLevel, level);
					} finally {
						DatabaseConnector.getInstance().getConn().setAutoCommit(true);
					}
					this.statNumSolverConfigs += numNewSC;
					this.listNewSC.addAll(tmpList);
					listBestSC.clear();
					log("c " + statNumSolverConfigs + "SC -> Generated " + numNewSC + " new solver configurations for level " + generateForLevel);

					for (SolverConfiguration sc : tmpList) {
						// add 1 random job from the best configuration with the
						// priority corresponding to the level
						// lower levels -> higher priorities
						addRandomJob(1, sc, bestSC, Integer.MAX_VALUE - generateForLevel);
						updateSolverConfigName(sc, false);
					}
				} else {
					Thread.sleep(2500);
				}
				// TODO : implement a method that determines an optimal wait
				// according to the runtimes of the jobs!

				for (int i = listNewSC.size() - 1; i >= 0; i--) {
					SolverConfiguration sc = listNewSC.get(i);
					// take only solver configs of the current level into
					// consideration
					// there might be some configs for the next level already
					// generated and evaluated
					if (sc.getLevel() == level) {
						currentLevelFinished = false;
					}
					cumulatedCPUTime += sc.updateJobsStatus();
					// updateSolverConfigName(sc, false);
					if (sc.getNumNotStartedJobs() + sc.getNumRunningJobs() == 0) {
						int comp = sc.compareTo(bestSC);
						if (comp >= 0) {
							if (sc.getJobCount() == bestSC.getJobCount()) {
								if (sc.getLevel() != level) {
									// don't add solver configurations from the
									// next level to the best sc list
									continue;
								}
								// all jobs from bestSC computed and won against
								// best:
								if (comp > 0) {
									listBestSC.add(sc);
									updateSolverConfigName(bestSC, false);
									bestSC = sc;
									sc.setIncumbentNumber(incumbentNumber++);
									updateSolverConfigName(bestSC, true);
									log("i " + getWallTime() + "," + sc.getCost() + ",n.A. ," + sc.getIdSolverConfiguration() + ",n.A. ," + sc.getParameterConfiguration().toString());
								
								}
								api.updateSolverConfigurationCost(sc.getIdSolverConfiguration(), sc.getCost(),
										statistics.getCostFunction());
								listNewSC.remove(i);
							} else {
								int generated = addRandomJob(sc.getJobCount(), sc, bestSC,
										Integer.MAX_VALUE - sc.getLevel());
								log("c Generated " + generated + " jobs for level " + sc.getLevel());
							}
						} else {// lost against best on part of the actual
								// parcours:
							if (deleteSolverConfigs)
								api.removeSolverConfig(sc.getIdSolverConfiguration());
							log("d Solver config " + sc.getIdSolverConfiguration() + " with cost " + sc.getCost() + " lost against best solver config on " + sc.getJobCount() + " runs.");
							if (sc.getLevel() == level) {
								numLostSC++;
								if (bestSC.getJobCount() < maxParcoursExpansionFactor * num_instances) {
									log("c Expanding parcours of best solver config " + bestSC.getIdSolverConfiguration() + " by 1");
									expandParcoursSC(bestSC, 1);
								}
							} else {
								numLostSCNextLevel++;
							}
							listNewSC.remove(i);// remove from new configurations
						}
					} else {
						if (useCapping) {
							// ---CAPPING RUNS OF BAD CONFIGS---
							// wenn sc schon eine kummulierte Laufzeit der
							// beendeten
							// jobs > der aller beendeten jobs von best
							// kann man sc vorzeitig beedenden! geht nur wenn
							// man parX hat!
							if ((this.statistics.getCostFunction() instanceof edacc.api.costfunctions.PARX) || (this.statistics.getCostFunction() instanceof edacc.api.costfunctions.Average))
								// TODO: minimieren / maximieren /negative
								// kosten
								if (sc.getCumulatedCost() > bestSC.getCumulatedCost()) {
									log("c " + sc.getCumulatedCost() + " >" + bestSC.getCumulatedCost());
									log("c " + sc.getJobCount() + " > " + bestSC.getJobCount());
									// kill all running jobs of the sc config!
									List<ExperimentResult> jobsToKill = sc.getJobs();
									for (ExperimentResult j : jobsToKill) {
										this.api.killJob(j.getId());
									}
									api.removeSolverConfig(sc.getIdSolverConfiguration());
									listNewSC.remove(i);
									log("c -----Config capped!!!");
								}
							// sc.killRunningJobs
							// api.removeSolverConfig(sc.)
						}
					}

				}
				// ----INCREASE PARALLELISM----
				// determine how many idleing cores we have and generate new
				// solver configurations for the next level
				
				if (!terminate() && generateSCForNextLevel) {
					int coreCount = api.getComputationCoreCount(idExperiment);
					if (coreCount < minCPUCount || coreCount > maxCPUCount) {
						log("w Warning: Current core count is " + coreCount);
					}
					int jobs = api.getComputationJobCount(idExperiment);
					int min_sc = Math.max(Math.round(4.f * coreCount), 8) - jobs;
					if (min_sc > 0) {
						int sc_to_generate = Math.max(Math.round(6.f * coreCount), 8) - jobs;
						generateNumSCForNextLevel = sc_to_generate;
					}
				}
				if (bestSC.getNumNotStartedJobs() + bestSC.getNumRunningJobs() != 0) {
					cumulatedCPUTime += bestSC.updateJobsStatus();
					updateSolverConfigName(bestSC, true);
					if (bestSC.getNumNotStartedJobs() + bestSC.getNumRunningJobs() == 0) {
						api.updateSolverConfigurationCost(bestSC.getIdSolverConfiguration(), bestSC.getCost(),
								statistics.getCostFunction());
					}
				}
				// determine and add race solver configurations
				for (SolverConfiguration sc : getRaceSolverConfigurations()) {
					log("c Found RACE solver configuration: " + sc.getIdSolverConfiguration() + " - " + sc.getName());
					addRandomJob(1, sc, bestSC, Integer.MAX_VALUE - level);
					updateSolverConfigName(sc, false);
					listNewSC.add(sc);
				}
				
			}
			/*updateSolverConfigName(bestSC, false);
			System.out.println("c Determining the new best solver config from " + listBestSC.size()
					+ " solver configurations.");
			if (listBestSC.size() > 0) {
				for (SolverConfiguration sc : listBestSC) {

					if (sc.compareTo(bestSC) > 0) {
						// if bestsc is from the same level as sc then remove
						// bestSC from DB as we want to keep only
						// 1 best from each level!
						
						//if (deleteSolverConfigs && (bestSC.getLevel() == sc.getLevel())
						//		&& (this.algorithm.equals("ROAR") || (this.algorithm.equals("MB")))) {
						//	api.removeSolverConfig(bestSC.getIdSolverConfiguration());
						//}
						bestSC = sc;
						
					} else {
						//if (deleteSolverConfigs && (this.algorithm.equals("ROAR") || (this.algorithm.equals("MB"))))
						//	api.removeSolverConfig(sc.getIdSolverConfiguration());
					}
				}
			}		*/
			if (!listBestSC.isEmpty()) {
				if (bestSC.getJobCount() < maxParcoursExpansionFactor * num_instances) {
					int exp = Math.min(maxParcoursExpansionFactor * num_instances - bestSC.getJobCount(), listBestSC.size());
					expandParcoursSC(bestSC, exp);
				}
			}
			// updateSolverConfigName(bestSC, true); not neccessary because we
			// update this in the beginning of the loop!
			log("c Ending level " + level);
		}

	}
	
	public float getWallTime() {
		return (System.currentTimeMillis() - startTime) / 1000.f;
	}

	/**
	 * Determines the solver configurations for which the user has set the race hint.<br/>
	 * Does not return solver configurations which have runs.
	 * @return
	 * @throws Exception
	 */
	public List<SolverConfiguration> getRaceSolverConfigurations() throws Exception {
		List<SolverConfiguration> res = new LinkedList<SolverConfiguration>();
		// get solver config ids
		List<Integer> solverConfigIds = api.getSolverConfigurations(idExperiment, "race");
		// reset hint field
		for (Integer i : solverConfigIds) {
			api.setSolverConfigurationHint(idExperiment, i, "");
		}
		// create solver configs and return them
		for (Integer i : solverConfigIds) {
			if (api.getRuns(idExperiment, i).isEmpty()) {
				try {
				SolverConfiguration sc = new SolverConfiguration(i, api.getParameterConfiguration(idExperiment, i), statistics, level);
				sc.setName(api.getSolverConfigName(i));
				res.add(sc);
				} catch (Exception e) {
					log("c getRaceSolverConfigurations(): invalid solver config: " + i);
				}
			}
		}
		return res;
	}
	
	public void shutdown() {
		log("c Solver Configurations generated: " + this.statNumSolverConfigs);
		log("c Jobs generated: " + statNumJobs);
		log("c Total runtime of the execution system (CPU time): " + cumulatedCPUTime);
		log("c Best Configuration found: ");
		log("c ID :" + bestSC.getIdSolverConfiguration());
		try {
			log("c Canonical name: "
					+ api.getCanonicalName(this.idExperiment, bestSC.getParameterConfiguration()));
		} catch (Exception e) {
			e.printStackTrace();
		}
		log("c halt.");
		api.disconnect();
	}

	/*public void updateSolverConfigName(SolverConfiguration sc, boolean best) throws Exception {
		api.updateSolverConfigurationName(
				sc.getIdSolverConfiguration(),
				(best ? " BEST " : "") + (sc.getName() != null ? " " + sc.getName() + " " : "") + sc.getIdSolverConfiguration() + " Runs: " + sc.getNumFinishedJobs()
						+ "/" + sc.getJobCount() + " Level: " + sc.getLevel()
						+ " " + api.getCanonicalName(idExperiment, sc.getParameterConfiguration()));
	}*/
	public void updateSolverConfigName(SolverConfiguration sc, boolean best) throws Exception {
		api.updateSolverConfigurationName(sc.getIdSolverConfiguration(), experimentName + " " + sc.getIncumbentNumber() + " " + sc.getCost());
	}

	/**
	 * Parses the configuration file and starts the configurator.
	 * 
	 * @param args
	 * @throws Exception
	 */
	public static void main(String[] args) throws Exception {
		if (args.length < 1) {
			System.out.println("Missing configuration file. Use java -jar PROAR.jar <config file path>");
			return;
		}
		PROARParameters params = new PROARParameters();
		Scanner scanner = new Scanner(new File(args[0]));

		while (scanner.hasNextLine()) {
			String line = scanner.nextLine();
			if (line.trim().startsWith("%"))
				continue;
			String[] keyval = line.split("=");
			String key = keyval[0].trim();
			String value = keyval[1].trim();
			if ("host".equals(key))
				params.hostname = value;
			else if ("user".equals(key))
				params.user = value;
			else if ("password".equals(key))
				params.password = value;
			else if ("port".equals(key))
				params.port = Integer.valueOf(value);
			else if ("database".equals(key))
				params.database = value;
			else if ("idExperiment".equals(key))
				params.idExperiment = Integer.valueOf(value);
			else if ("seed".equals(key))
				params.seed = Long.valueOf(value);
			else if ("jobCPUTimeLimit".equals(key))
				params.jobCPUTimeLimit = Integer.valueOf(value);
			else if ("algorithm".equals(key))
				params.algorithm = value;
			else if ("costFunction".equals(key))
				params.costFunc = value;
			else if ("minimize".equals(key))
				params.minimize = Boolean.parseBoolean(value);
			else if ("parcoursExpansion".equals(key))
				params.pe = Integer.valueOf(value);
			else if ("maxParcoursExpansionFactor".equals(key))
				params.mpef = Integer.valueOf(value);
			else if ("initialParcoursDefault".equals(key))
				params.ipd = Integer.valueOf(value);
			else if (key.startsWith(params.algorithm + "_")) 
				params.configuratorMethodParams.put(key, value);
			else if (key.equals("maxTuningTime")) 
				params.maxTuningTime = Integer.valueOf(value);
			else if (key.equals("minCPUCount")) 
				params.minCPUCount = Integer.valueOf(value);
			else if (key.equals("maxCPUCount"))
				params.maxCPUCount = Integer.valueOf(value);
			
			
		}
		scanner.close();
		System.out.println("c Starting the PROAR configurator with following settings: \n" + params);
		System.out.println("c ---------------------------------");
		PROAR configurator = new PROAR(params);
		configurator.start();
		configurator.shutdown();
	}

	public void log(String message) {
		System.out.println("[Date: " +new Date() + ",Walltime: " + getWallTime() + ",CPUTime: " + cumulatedCPUTime + ",NumSC: " + statNumSolverConfigs + ",NumJobs: " + statNumJobs + "] " + message);
	}

}
class PROARParameters {
	String hostname = "", user = "", password = "", database = "";
	int idExperiment = 0;
	int port = 3306;
	int jobCPUTimeLimit = 13;
	long seed = System.currentTimeMillis();
	String algorithm = "ROAR";
	String costFunc = "par10";
	boolean minimize = true;
	int pe = 1;
	int mpef = 5;
	int ipd = 10;
	int minCPUCount = 0;
	int maxCPUCount = 0;
	float maxTuningTime = -1;
	StatisticFunction statFunc;
	HashMap<String, String> configuratorMethodParams = new HashMap<String, String>();
	
	public String toString() {
		String paramsForAlgo = "";
		for (String key : configuratorMethodParams.keySet()) {
			paramsForAlgo += "(" + key + "," + configuratorMethodParams.get(key) + ") ";
		}
		return  "c Host: " + user + ":xxxxx" + "@" + hostname + ":" + port + "/" + database + "\n" +
				"c Experiment Id: " + idExperiment + "\n" +
				"c Algorithm: " + algorithm + "\n" +
				"c Optimizing statistic: " + costFunc + "\n" +
				"c towards: " + (minimize ? "mimisation" : "maximisation") + "\n" +
				"c Parcours expansion pro level: " + pe + "\n" +
				"c Maximum parcours expansion factor: " + mpef + "\n" +
				"c Initial Parcours for first config: " + ipd + "\n" +
				"c CPU time limit: " + jobCPUTimeLimit + "\n" +
				"c Maximum tuning time: " + (maxTuningTime == -1 ? "unlimited" : maxTuningTime) + "\n" +
				"c Seed: " + seed + "\n" +
				"c Parameters for algorithm: " + paramsForAlgo + "\n";
	}
}
